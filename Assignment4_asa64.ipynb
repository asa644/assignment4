{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will build a multi-class SVM classifier for text classification. You will first need to import the libraries. Then you will need to pre-process your data by removing stop words and stemming. After\n",
    "cleaning the data, you will give each word a weight using tf-idf. Those weights will be used as features for your classifier. You will split your data into training (80%) and testing (20%). Then, you will train different SVM classifiers and find the best model using a 10-fold cross-validation. Also, you should save your best model and test your model on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from __future__ import print_function\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = pandas.read_csv(\"Tweets.csv\", usecols=[1], encoding=\"Latin1\").values.flatten()\n",
    "y = pandas.read_csv(\"Tweets.csv\", usecols=[0], encoding=\"Latin1\").values.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Pre-process your data by removing stop words and perform stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = str.maketrans({key: None for key in string.punctuation})\n",
    "# new_s = s.translate(table)                          # Output: string without punctuation\n",
    "result = []\n",
    "for sentence in x:\n",
    "    sentence = sentence.translate(table)\n",
    "    sentence = sentence.split()\n",
    "    sentence = [w for w in sentence if w.lower() not in stopwords.words('english') ]\n",
    "    result.append(sentence)\n",
    "    \n",
    "ps = PorterStemmer()\n",
    "result2 = []\n",
    "for sentence in result:\n",
    "    sentence2 = []\n",
    "    for word in sentence:\n",
    "        sentence2.append(ps.stem(word))\n",
    "    result2.append(sentence2)\n",
    "x = []\n",
    "for sentence in result2:\n",
    "    x.append(\" \".join(str(y) for y in sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split your data into training (80%) and testing (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform your cleaned textual training data to give for each word a weight using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,3), min_df = 0, stop_words = 'english')\n",
    "X_train = tf.fit_transform(X_train)\n",
    "# X_test = tf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save TF-IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the tf-idf learnt from the textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf = pickle.dump(tf, open(\"tfidf.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is your data linearly separable? Verify using a hard margin SVM and explain why/why not ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a multi-class hard margin SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995987021858\n"
     ]
    }
   ],
   "source": [
    "reg = LinearSVC(C=1000)\n",
    "reg.fit(X_train, y_train)\n",
    "accuracy = reg.score(X_train, y_train)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The accuracy is 99%, therefore, it's linearly separable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to try the following different models: a hard margin SVM classifier with polynomial Kernel and a hard margin SVM classifier with RBF kernel. For each, set the values of the different hyperparameters using an Exhaustive Grid Search Cross-Validation. Report the number of support vectors in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for poly:\n",
      "best_score: 0.764173497268\n",
      "# of support vectors [5774 2441 1646]\n",
      "Degree 1\n",
      "Gamma 0.1\n",
      "for rbf:\n",
      "best_score: 0.764856557377\n",
      "# of support vectors [5871 2443 1648]\n",
      "Degree 1\n",
      "Gamma 0.1\n"
     ]
    }
   ],
   "source": [
    "gamma = [0.1, 1, 10, 100]\n",
    "degree = [1, 2, 3]\n",
    "svc_poly = SVC()\n",
    "params = {'kernel':['poly'], 'C':[1000], 'gamma': gamma, 'degree': degree}\n",
    "clf_poly = GridSearchCV(svc_poly, params)\n",
    "clf_poly.fit(X_train, y_train)\n",
    "best = clf_poly.best_score_\n",
    "print(\"for poly:\")\n",
    "print(\"best_score:\", best)\n",
    "print(\"# of support vectors\",clf_poly.best_estimator_.n_support_)\n",
    "print(\"Degree\", clf_poly.best_estimator_.degree)\n",
    "print(\"Gamma\", clf_poly.best_estimator_.gamma)\n",
    "svc_rbf = SVC()\n",
    "params = {'kernel':['rbf'], 'C':[1000], 'gamma': gamma, 'degree': degree}\n",
    "clf_rbf = GridSearchCV(svc_rbf, params)\n",
    "clf_rbf.fit(X_train, y_train)\n",
    "best = clf_rbf.best_score_\n",
    "print(\"for rbf:\")\n",
    "print(\"best_score:\", best)\n",
    "print(\"# of support vectors\",clf_rbf.best_estimator_.n_support_)\n",
    "print(\"Degree\", clf_rbf.best_estimator_.degree)\n",
    "print(\"Gamma\", clf_rbf.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above using a soft margin SVM classifier for all the cases, including the linear one, and again set the hyperparameters using an Exhaustive Grid Search Cross-Validation. Report the number of support vectors in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear:\n",
      "best_score: 0.765454234973\n",
      "# of support vectors [5747 2444 1646]\n",
      "Poly:\n",
      "best_score: 0.765454234973\n",
      "# of support vectors [5747 2444 1646]\n",
      "Degree 1\n",
      "Gamma 100\n",
      "Poly:\n",
      "best_score: 0.768015710383\n",
      "# of support vectors [5780 2432 1630]\n",
      "Degree 1\n",
      "Gamma 0.1\n"
     ]
    }
   ],
   "source": [
    "C = [0.1, 1, 10, 100]\n",
    "params_lin = params = {'kernel':['linear'], 'C': C}\n",
    "params_poly = params = {'kernel':['poly'], 'C': C, 'gamma': gamma, 'degree': degree}\n",
    "params_rbf = params = {'kernel':['rbf'], 'C': C, 'gamma': gamma, 'degree': degree}\n",
    "svc_lin = SVC()\n",
    "clf_lin = GridSearchCV(svc_lin, params_lin)\n",
    "clf_lin.fit(X_train, y_train)\n",
    "best = clf_lin.best_score_\n",
    "print(\"Linear:\")\n",
    "print(\"best_score:\", best)\n",
    "print(\"# of support vectors\",clf_lin.best_estimator_.n_support_)\n",
    "# print(\"Degree\", clf_lin.best_estimator_.degree)\n",
    "# print(\"Gamma\", clf_lin.best_estimator_.gamma)\n",
    "\n",
    "svc_poly = SVC()\n",
    "clf_poly = GridSearchCV(svc_poly, params_poly)\n",
    "clf_poly.fit(X_train, y_train)\n",
    "best = clf_poly.best_score_\n",
    "print(\"Poly:\")\n",
    "print(\"best_score:\", best)\n",
    "print(\"# of support vectors\",clf_poly.best_estimator_.n_support_)\n",
    "print(\"Degree\", clf_poly.best_estimator_.degree)\n",
    "print(\"Gamma\", clf_poly.best_estimator_.gamma)\n",
    "\n",
    "svc_rbf = SVC()\n",
    "clf_rbf = GridSearchCV(svc_rbf, params_rbf)\n",
    "clf_rbf.fit(X_train, y_train)\n",
    "best = clf_rbf.best_score_\n",
    "print(\"Rbf:\")\n",
    "print(\"best_score:\", best)\n",
    "print(\"# of support vectors\",clf_rbf.best_estimator_.n_support_)\n",
    "print(\"Degree\", clf_rbf.best_estimator_.degree)\n",
    "print(\"Gamma\", clf_rbf.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your best SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soft_rbf = pickle.dump(clf_rbf, open(\"best_model.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your tf-idf to transform your test data to give for each word a weight. Then load your best SVM classifier and plot the confusion matrix of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Rename the jupyter notebook to Assignment4_*netid*.ipynb (Assignment4_xyz01.ipynb) and upload it on Moodle no later than Wednesday, Nov 8 11:55 pm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
